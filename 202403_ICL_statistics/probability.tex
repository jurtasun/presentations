\documentclass{book}

\usepackage{makeidx}
\usepackage{indentfirst}
\usepackage{amsmath}
\usepackage[margin=1in]{geometry} 

\makeindex

\begin{document}

\frontmatter

\begin{titlepage}
    \centering
    \vspace*{\fill}
    {\Huge\bfseries Introduction to probability theory and statistical inference\par}
    \vspace{1cm}
    {\Large Jes\'us Urtasun Elizari\par}
    \vspace{1cm}
     {\Large Imperial College London\par}
    \vspace{1cm}
    {\large\today\par}
    \vspace*{\fill}
\end{titlepage}

\tableofcontents

\chapter*{Index}
\addcontentsline{toc}{chapter}{Index}
\printindex

\mainmatter

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

\section{Background}
\indent In the following pages one will find an introductory text to one of the key subjects within mathematical sciences. The text is composed by four chapters, together with some appendix reviewing basic mathematical concepts, and a bibliographic note. The purpose of this lecture notes is to make both probability and statistical analysis an easy, interesting and engaging topic for anyone interested, without the need for prior experience with mathematical training.\\

First, we will introduce and explore the concept of probability itself, and we will discuss how to model information, surprise, and various random processes, also referred to as \textit{stochastic}. Then we will introduce the idea of a function and how functions need to be adapted to implement uncertainty when discussing random events.\\

In the second part we will address the difference between prediction and inference, and discuss a set of subjects normally grouped under the name of hypothesis testing. Here we will introduce how to quantify certainty and bias, and how to model significance and false positives, that is, to compute p-values.\\

Finally, we will discuss bayesian statistics.

\chapter{Introduction to probability theory}

\section{What is probability?}
Probability theory is one of the oldest subjects within mathematical studies. Paradoxically, almost every topic explained nowadays in modern courses of statistics is extremely new, ranging broadly a century. (...)\\

So let's first ask ourselves the question. What \textit{is} probability in the first place? What do we mean by it and what does it describe? Probability is nothing more, and nothing less, that a number we make up, a quantity we come up with, to quantify certainty. A number we will use to describe the amount of information we have about a random, or stochastic, event. For simplicity, we can make it range from 0 to 1, in the following way.

\begin{itemize}
\item If I'm sure A will never happen, P(A) = 0.
\item If I'm sure A will always happen,  P(A) = 1.
\item Anything in between, if exists degree of surprise, P(A) in [0, 1]
\end{itemize}

\begin{equation}
	\sum_{i = 0}^{n} \; p(x_{i}) = 1
\end{equation}

Once we have a definition for probability in the abstract case, we should have a way to compute for particular cases. A way of doing that, referred to as frequentist approach, is by dividing the number of favorable outcomes by the total number of outcomes.

\begin{equation}
	P(\text{A happening}) = \frac{\text{Number of times A happens}}{\text{Total number of trials}}
\end{equation}

Probabilities must follow a property we call unitarity.


Unitarity ensures that, if we consider and add up the probabilities for all possible events in a given experiment, we get the total. That means, at least one of the scenarios will happen.\\

Indeed, the literal meaning of probability comes from latin probabilis. American logician and philosopher Richard Jeffrey, "Before the middle of the seventeenth century, the term "probable" (Latin probabilis) meant just approvable, and was applied in that sense, univocally, to opinion and to action. A probable action or opinion was one such as sensible people would undertake or hold, in the circumstances."[12] However, in legal contexts especially, "probable" could also apply to propositions for which there was good evidence.\\

The sixteenth-century Italian polymath Girolamo Cardano demonstrated the efficacy of defining odds as the ratio of favourable to unfavourable outcomes (which implies that the probability of an event is given by the ratio of favourable outcomes to the total number of possible outcomes[14]). Aside from the elementary work by Cardano, the doctrine of probabilities dates to the correspondence of Pierre de Fermat and Blaise Pascal (1654). Christiaan Huygens (1657) gave the earliest known scientific treatment of the subject.[15] Jakob Bernoulli's Ars Conjectandi (posthumous, 1713) and Abraham de Moivre's Doctrine of Chances (1718) treated the subject as a branch of mathematics.[16] See Ian Hacking's The Emergence of Probability[10] and James Franklin's The Science of Conjecture[17] for histories of the early development of the very concept of mathematical probability.\\

Like other theories, the theory of probability is a representation of its concepts in formal terms â€“ that is, in terms that can be considered separately from their meaning. These formal terms are manipulated by the rules of mathematics and logic, and any results are interpreted or translated back into the problem domain.\\

There have been at least two successful attempts to formalize probability, namely the Kolmogorov formulation and the Cox formulation. In Kolmogorov's formulation (see also probability space), sets are interpreted as events and probability as a measure on a class of sets. In Cox's theorem, probability is taken as a primitive (i.e., not further analyzed), and the emphasis is on constructing a consistent assignment of probability values to propositions. In both cases, the laws of probability are the same, except for technical details.\\


\section{Discrete probability distributions}
Once we are comfortable with the idea of random events, and we have been introduced to probability as a number to quantify surprise, we can agree that not all random phenomena are equal. A basic way to classify and separate random events is according to how their probabilities are distributed.

\subsection{Binomial distribution}
What is the probability of obtaining $x$ successes in $N$ trials, if the probability of success each time is $p$


\subsection{Poisson distribution}
What is the probability of counting $x$ events in a time interval, if the observed average is given by $\lambda$

\section{Continuous probability distributions}
Your content for Chapter 1 goes here.

\subsection{Uniform distribution}
Uniform distribution

\subsection{Exponential distribution}
Exponential distribution

\subsection{Gaussian distribution}
Gaussian distribution

\chapter{Linear models}

\section{Functions and variables}
Probability theory is one of the oldest subjects within mathematical studies. Paradoxically, almost every topic explained nowadays in modern courses of statistics is extremely new, ranging broadly a century. (...)\\

So let's first ask ourselves the question. What is probability in the first place? What do we mean by it and what does it describe? Probability is nothing more, and nothing less, that a number we make up, a quantity we come up with, to quantify certainty. A number we will use to describe the amount of information we have about a random, or stochastic, event. For simplicity, we can make it range from 0 to 1, in the following way.


\section{Modelling uncertainty in random events}
Your content for Chapter 2 goes here.

\chapter{Introduction to statistical inference}

\section{Hypothesis testing}
Probability theory is one of the oldest subjects within mathematical studies. Paradoxically, almost every topic explained nowadays in modern courses of statistics is extremely new, ranging broadly a century. (...)\\

So let's first ask ourselves the question. What is probability in the first place? What do we mean by it and what does it describe? Probability is nothing more, and nothing less, that a number we make up, a quantity we come up with, to quantify certainty. A number we will use to describe the amount of information we have about a random, or stochastic, event. For simplicity, we can make it range from 0 to 1, in the following way.


\section{The idea of significance and p-values}
Your content for Chapter 3 goes here.

\section{Parametric and non parametric tests}
Your content for Chapter 3 goes here.

\chapter{Introduction to bayesian statistics}

\section{Frequentist and bayesian approach}
Probability theory is one of the oldest subjects within mathematical studies. Paradoxically, almost every topic explained nowadays in modern courses of statistics is extremely new, ranging broadly a century. (...)\\

So let's first ask ourselves the question. What is probability in the first place? What do we mean by it and what does it describe? Probability is nothing more, and nothing less, that a number we make up, a quantity we come up with, to quantify certainty. A number we will use to describe the amount of information we have about a random, or stochastic, event. For simplicity, we can make it range from 0 to 1, in the following way.

\section{Bayesian statistics}
Your content for Chapter 4 goes here.

\backmatter

\chapter*{Bibliography}
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{plain} % Choose your bibliography style
\bibliography{your_bibliography_file} % Replace with your actual .bib file

\end{document}